Что имеем. 

Логику трёх парсеров которые могут работать по тесту до суток(больше по времени не проверял, из-за рандомный засыпаний, заголовков.) Блока не было по сайтам. 

Так как количество запросов ограничено в определённое время (у каждого сайто своё). 

Не имеет смысла делать запрос с FastApi в один из трёх фоновый парсеров, 
(можно реализовать и на них, но это будет добавление в очередь и по кнопке будет обновлена информация в течение времени, которое потребуется, для обработки ранее добавленых объявлений.)

Так как кнопка обновить в ручную, является не общим функционалом. 
Запрос с них(url, uuid) будет передан в спамогательный парсер для получения html контента страницы. После контент будет разобран методами фоновых парсеров. 

1. Написать фоновый парсер запросов с использование прокси и headrs(прокси идёт по листу как начинает заканчиваться парсит новый и проверяет актуальность), user-agent смена при каждой закрытой ссесии. 

2. После получение супа передать в метод фонового парсера для разбора страницы и получения данных. 

3. подключить к FastApi.